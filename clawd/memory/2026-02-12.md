# 2026-02-12 (수요일 → 목요일 KST)

## Sol Park 회신 메일 발송 완료
- Jay가 직접 Sol Park (solpark@google.com)에게 회신 보냄 (17:43 KST)
- 내용: 아쉽지만 이해한다, 향후 적합한 포지션 생기면 연락 달라
- "다시 연락주겠다"는 예의상 반반 → 레퍼럴 관계 유지가 더 중요

## 주식 매도 + 환전
- 달러 주식 매도 → 한화 환전 완료
- 1,000만원 확보 (연말정산 세금 납부용)
- 환율 약 1,445원대 (최근 1개월 중 낮은 수준, 원화 강세)

## 용과같이 극 1 (Yakuza Kiwami) 플레이 중
- 총 13챕터, 현재 8챕터 진행 중
- (이전: 용과같이 0 플레이 중이었는데 극 1로 넘어감)

## paper-finder 스킬 구현 완료 🎉
- **목적:** PoC 기술 구현의 학술적 근거 논문 검색
- **트리거:** `/paper <키워드>` 또는 자연어
- **검색 소스:** Semantic Scholar API (primary) + web_search (fallback) + Papers with Code
- **출력:** 원조 논문 1개 + 최신 2개, 인용 수/URL/요약/PoC 적용 포인트
- **저장:** `docs/papers/YYYY-MM-DD-<topic>.md`
- **파일:** `skills/paper-finder/SKILL.md`, `docs/plans/2026-02-12-paper-finder-design.md`
- **커밋:** 384bef6
- **참고:** Semantic Scholar search API는 rate limit 빡빡 (429 자주 발생), 개별 paper lookup은 괜찮음

## OpenClaw memory_search 로컬 임베딩 발견
- OpenClaw config schema에서 `memorySearch` 설정 확인
- **provider 옵션:** `openai`, `local`, `gemini`, `voyage`
- **`local` provider:** node-llama-cpp 사용, GGUF 모델 지원
  - `local.modelPath` → GGUF 파일 경로 또는 `hf:` URI (예: `hf:nomic-ai/nomic-embed-text-v1.5-GGUF`)
  - `local.modelCacheDir` → 모델 캐시 디렉토리
- **store:** SQLite 기반, vector 검색 기본 enabled
- **추천:** `local` provider로 무료 + 외부 의존 없이 활성화 가능
- **상태:** ✅ 활성화 완료!

## memory_search 로컬 임베딩 활성화 (04:08 KST → 13:08 KST)
- Jay가 인스턴스 t3.medium → **t3.xlarge** 업그레이드 해줌 (4 vCPU, 16GB RAM)
- `config.patch`로 memorySearch 설정 추가:
  - `provider: "local"`
  - `modelPath: "hf:nomic-ai/nomic-embed-text-v1.5-GGUF"`
- 모델 자동 다운로드 완료 (48MB GGUF, Q2_K quantization)
- 테스트 성공: "Google Cloud CE rejection Sol Park" 검색 → 관련 메모리 6건 정확히 검색됨
- **동작 방식:** lazy indexing — 파일 저장 시 임베딩 안 하고, memory_search 호출 시 변경 감지 → 그때 임베딩 생성
- **비용:** 0원 (로컬 모델, 외부 API 의존 없음)
- Bedrock Cohere Embed v4는 OpenClaw이 네이티브 미지원 (provider: openai/local/gemini/voyage만)
