# 2026-02-10 (월요일)

## GCP 인터뷰 진행 상황

### 메일 확인
- **Daeun Jeong의 초대 메일** (2/9 16:48 KST)
  - RRK 인터뷰 초대 (45분)
  - 4라운드: RRK → GCA → G&L → Presentation
  - 각 라운드 elimination (탈락 가능)
  - ⚠️ AI 사용 금지 (적발 시 실격)
  - PDF 첨부: Interview Prep Guide (AI/ML Specialist RRK Material), Virtual Interview Guide

- **Jay의 답신** (2/9 17:05 KST)
  - 가능 일정 제시:
    - 2/11 (수) 13:30-17:00
    - 2/12 (목) 09:00-11:00
    - 2/13 (금) 09:00-17:00
    - 2/19-20: 휴가 예정, 필요시 2/19 오후 가능
  - Daeun의 회신 대기 중 (2/10 오전 현재)

---

## 기술 개념 학습

### OpenSearch K-NN
- **K-NN (k-Nearest Neighbors)**: k개의 가장 가까운 이웃 찾기
- **용도**: 벡터 검색 (RAG), 추천 시스템, 이미지 검색
- **작동**: 질문 벡터와 문서 벡터 간 거리 계산 → 가장 가까운 k개 반환
- **거리 측정**: Euclidean (직선), Cosine (방향), Inner Product
- **2가지 방식**:
  - Exact K-NN: 모든 벡터 비교 (정확, 느림)
  - Approximate K-NN (HNSW): 인덱스로 빠르게 검색 (95-99% 정확, 빠름)

### HNSW vs Faiss
- **HNSW**: 알고리즘 (Hierarchical Navigable Small World)
  - 그래프 기반 벡터 검색
  - OpenSearch, Pinecone, Weaviate에서 사용
- **Faiss**: 라이브러리 (Facebook AI Similarity Search)
  - Meta가 만든 벡터 검색 구현체
  - 여러 알고리즘 포함 (HNSW, IVF, PQ 등)
  - OpenSearch K-NN 플러그인에서 선택 가능
- 비유: HNSW = 길찾기 알고리즘, Faiss = 내비게이션 앱

### Kubeflow
- **무엇**: Kubernetes 위의 ML 플랫폼 (오픈소스)
- **핵심 컴포넌트**:
  - Kubeflow Pipelines (KFP): ML 워크플로우 자동화
  - Katib: 하이퍼파라미터 튜닝
  - Training Operators: 분산 학습 (TFJob, PyTorchJob)
  - Notebook: JupyterHub on K8s
  - KServe: 모델 서빙
- **vs SageMaker**: 오픈소스 vs 매니지드, 멀티클라우드 vs AWS 종속
- **GCP**: Vertex AI Pipelines는 Kubeflow Pipelines 기반! ✅
- **언제 사용**: 멀티클라우드, 온프렘+클라우드 하이브리드, K8s 전문 팀

### Googleyness (6가지 원칙)
1. **Comfort with Ambiguity**: 모호함 속에서도 진전, "일단 시도"
2. **Bias to Action**: 완벽한 계획보다 빠른 실행, "Done > Perfect"
3. **Collaborative**: 팀 성공 > 개인, "We" > "I"
4. **Intellectual Humility**: 내가 틀릴 수 있음 인정, 더 나은 의견에 마음 바꿈
5. **Courage**: 어려운 결정, 실패 두려워하지 않음, 상사에게도 반대 의견
6. **Conscientiousness**: 맡은 일 책임감, 디테일, 약속 지킴

- **STAR 형식**: Situation → Task → Action → Result
- **준비**: 각 원칙별 1-2개 스토리 준비 필요

### RRK 답변 프레임워크 ⭐
- **Notion 섹션 추가 완료** (2/10 오전)
- **5단계**:
  1. 문제 명확화 (Clarify): "확인하고 싶은 게..."
  2. 구조화 (Structure): "3가지 측면으로..."
  3. 답변 (Answer): What/How/When/Trade-offs/GCP-AWS 매핑
  4. 경험 연결 (Experience): AWS 실무 경험
  5. 확인 (Validate): "더 설명드릴까요?"
- **❌ 즉답 금지**: 오만, 비구조적
- **✅ 구조화**: Googleyness (지적 겸손 + 구조적 사고) 보여주기
- **시간**: 질문당 5분 내외 (45분에 8-9개 질문)

### LoRA 가중치 개념
- **가중치(Weights)**: 신경망의 학습 가능한 파라미터 (숫자들)
- **일반 Fine-tuning**: 70억 개 가중치 모두 업데이트 (메모리 폭발)
- **LoRA**: W_new = W_old + (A × B)
  - W: 원래 가중치 (frozen, 고정)
  - A, B: 저차원 행렬 (작음, rank=8-16)
  - A × B ≈ ΔW (가중치 변화량)
- **효율**: 256배 메모리 절약 (16M → 6만 개)
- **핵심 통찰**: Fine-tuning 시 가중치 변화는 저차원 구조를 가짐

---

## 고객 미팅용 기술 조사

### ViT / ResNet (건설 결함 탐지)
- **유스케이스**: 균열, 누수, 도장불량, 타일파손, 결로 자동 탐지

**ResNet-50:**
- 2015년 Microsoft, CNN 기반
- Skip Connection으로 깊게 쌓기 (50/101/152 layers)
- 장점: 빠름, 검증됨, 작은 데이터셋 OK
- 단점: ViT보다 정확도 낮음

**ViT (Vision Transformer):**
- 2020년 Google, Transformer 기반
- 이미지를 패치로 나눔 → Self-Attention
- 장점: 최고 정확도 (대규모 데이터 시)
- 단점: 데이터 많이 필요, 느림

**Fine-tuning:**
- Pre-trained 모델 (ImageNet) + 고객 데이터 수백 장
- 마지막 레이어만 재학습
- "고양이 vs 개" 지식 → "균열 vs 정상"

**추천:**
- 소규모 (수백-천 장): ResNet-50
- 대규모 (만 장+): ViT
- 실무: 둘 다 A/B 테스트

### YOLO (영상 처리)
- **무엇**: 객체 탐지 (Object Detection) 모델
- **출력**: Bounding Box + 클래스 (사람, 헬멧, 안전조끼 등)
- **비디오 처리**: 프레임별로 YOLO 실행
  - 30 FPS 비디오 = 초당 30장 이미지 처리
  - YOLOv8: < 10ms (GPU), 실시간 가능
- **왜 엣지?**:
  - 비용 절감 (정상 상황은 로컬만, 이상 시만 클라우드)
  - 저지연 (10-50ms vs 500ms)
  - 프라이버시 (민감 영상 안 전송)
- **버전**: YOLOv5n/YOLOv8n (엣지 최적)
- **엣지 HW**: Jetson Nano/Xavier, Coral TPU, Raspberry Pi

### AWS IoT Core vs Greengrass
**IoT Core (클라우드):**
- AWS의 MQTT Broker + 디바이스 관리
- 항상 인터넷 필요
- 지연시간 높음 (100-500ms)

**Greengrass (엣지):**
- 엣지 디바이스에 설치하는 소프트웨어
- Lambda, ML 모델을 **로컬 실행**
- 오프라인 작동 가능
- 저지연 (< 10ms)
- 이상 시에만 IoT Core로 전송
- 비용 절감 (로컬 처리 → 메시지 적음)

**CCTV 안전 감지 구조:**
```
CCTV → Greengrass (YOLO Lambda 로컬) → 정상: 로컬만
                                      → 이상: IoT Core 알림
```

**GCP 비교:**
- AWS IoT Core ≈ Cloud IoT Core (deprecated)
- AWS Greengrass ≈ Edge TPU/Coral + 커스텀 소프트웨어

---

## Notion 업데이트
- "8. RRK 답변 프레임워크" 섹션 추가 (2/10 오전)
  - 즉답 vs 구조화 비교
  - 5단계 프레임워크
  - 시간 배분
  - 실수 피하기

---

## 다음 액션
- [ ] Daeun의 인터뷰 일정 확정 대기 (이번 주 수/목/금 중)
- [ ] GCA, G&L YouTube 영상 시청
- [ ] PDF 가이드 확인 (AI/ML RRK Material)
- [ ] Googleyness 스토리 각 1-2개씩 준비
- [ ] RRK 질문 1-15번 모의 답변 연습 (5단계 프레임워크 적용)

---
