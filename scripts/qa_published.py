#!/usr/bin/env python3
"""qa_published.py â€” ë°°í¬ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìµœì¢… ê²€ìˆ˜

ê²€ìˆ˜ í•­ëª©:
1. í…ìŠ¤íŠ¸ ê²€ì‚¬: LaTeX, SVG, [DIAGRAM] í”Œë ˆì´ìŠ¤í™€ë”, ì„¹ì…˜ ìˆ˜
2. ì´ë¯¸ì§€ ì ‘ê·¼ ê²€ì‚¬: ë‹¤ì´ì–´ê·¸ë¨ PNG URL HTTP 200 í™•ì¸
3. Dead link ê²€ì‚¬: ë³¸ë¬¸ ë‚´ ì™¸ë¶€ ë§í¬ ì ‘ê·¼ì„±
4. AI ë¬¸ì²´ ê²€ì‚¬: humanizer íŒ¨í„´ (ê³¼ì¥, ë°˜ë³µ, ë°˜ë§ ë“±)
5. ìŠ¤í¬ë¦°ìƒ·: Playwrightë¡œ ì‹¤ì œ ë Œë”ë§ ìº¡ì²˜ (ì„ íƒ)

Usage:
  python3 qa_published.py --url <published_url> [--post <local_md_path>] [--screenshot]
"""

import argparse
import json
import logging
import re
import sys
import time
from pathlib import Path
from urllib.parse import urljoin, unquote

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("qa_published")

# â”€â”€ ê²€ìˆ˜ ê²°ê³¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class QAResult:
    def __init__(self):
        self.checks = []
        self.errors = []
        self.warnings = []

    def error(self, category, msg):
        self.errors.append({"category": category, "message": msg})
        self.checks.append({"category": category, "status": "ERROR", "message": msg})
        logger.error("âŒ [%s] %s", category, msg)

    def warn(self, category, msg):
        self.warnings.append({"category": category, "message": msg})
        self.checks.append({"category": category, "status": "WARN", "message": msg})
        logger.warning("âš ï¸ [%s] %s", category, msg)

    def ok(self, category, msg):
        self.checks.append({"category": category, "status": "OK", "message": msg})
        logger.info("âœ… [%s] %s", category, msg)

    @property
    def passed(self):
        return len(self.errors) == 0

    def summary(self):
        total = len(self.checks)
        errors = len(self.errors)
        warnings = len(self.warnings)
        oks = total - errors - warnings
        return f"ê²€ìˆ˜ ì™„ë£Œ: {total}ê±´ ({oks} OK, {warnings} WARN, {errors} ERROR)"


# â”€â”€ 1. í…ìŠ¤íŠ¸ ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_text(content: str, result: QAResult):
    """ë°°í¬ëœ í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ì”ì¡´ ì½”ë“œ/ë§ˆí¬ì—… ê²€ì‚¬"""

    # LaTeX $...$ ì”ì¡´
    latex_matches = re.findall(r"\$[^$]{3,}\$", content)
    if latex_matches:
        result.error("TEXT_LATEX", f"LaTeX ìˆ˜ì‹ {len(latex_matches)}ê°œ ì”ì¡´: {latex_matches[0][:50]}...")
    else:
        result.ok("TEXT_LATEX", "LaTeX ìˆ˜ì‹ ì—†ìŒ")

    # <svg> íƒœê·¸ ì”ì¡´
    svg_count = content.lower().count("<svg")
    if svg_count > 0:
        result.error("TEXT_SVG", f"<svg> íƒœê·¸ {svg_count}ê°œ ì”ì¡´")
    else:
        result.ok("TEXT_SVG", "SVG íƒœê·¸ ì—†ìŒ")

    # [DIAGRAM: ...] í”Œë ˆì´ìŠ¤í™€ë” ì”ì¡´
    diagram_placeholders = re.findall(r"\[DIAGRAM:[^\]]*\]", content)
    if diagram_placeholders:
        result.error("TEXT_DIAGRAM", f"[DIAGRAM] í”Œë ˆì´ìŠ¤í™€ë” {len(diagram_placeholders)}ê°œ ì”ì¡´")
    else:
        result.ok("TEXT_DIAGRAM", "[DIAGRAM] í”Œë ˆì´ìŠ¤í™€ë” ì—†ìŒ")

    # ```svg ë˜ëŠ” ```mermaid ì½”ë“œ ë¸”ë¡ ì”ì¡´
    code_blocks = re.findall(r"```(?:svg|mermaid)", content)
    if code_blocks:
        result.error("TEXT_CODEBLOCK", f"svg/mermaid ì½”ë“œ ë¸”ë¡ {len(code_blocks)}ê°œ ì”ì¡´")
    else:
        result.ok("TEXT_CODEBLOCK", "svg/mermaid ì½”ë“œ ë¸”ë¡ ì—†ìŒ")

    # ì„¹ì…˜ ìˆ˜ í™•ì¸ (ìµœì†Œ 3ê°œ = 2 ë³¸ë¬¸ + References)
    sections = re.findall(r"^#{2}\s+.+", content, re.MULTILINE)
    # HTML headings fallback
    if not sections:
        sections = re.findall(r"<h[23][^>]*>(.+?)</h[23]>", content, re.IGNORECASE)
    if len(sections) < 3:
        result.warn("TEXT_SECTIONS", f"ì„¹ì…˜ {len(sections)}ê°œ (ìµœì†Œ 3ê°œ ê¶Œì¥)")
    else:
        result.ok("TEXT_SECTIONS", f"ì„¹ì…˜ {len(sections)}ê°œ")

    # ë¶„ëŸ‰ í™•ì¸ (ìµœì†Œ 3000ì)
    if len(content) < 3000:
        result.warn("TEXT_LENGTH", f"ë¶„ëŸ‰ {len(content)}ì (ìµœì†Œ 3000ì ê¶Œì¥)")
    else:
        result.ok("TEXT_LENGTH", f"ë¶„ëŸ‰ {len(content)}ì")


# â”€â”€ 2. ì´ë¯¸ì§€ ì ‘ê·¼ ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_images(content: str, base_url: str, result: QAResult):
    """ë³¸ë¬¸ ë‚´ ì´ë¯¸ì§€ URL ì ‘ê·¼ì„± í™•ì¸"""
    import requests

    # ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ ì°¸ì¡° ì¶”ì¶œ
    img_refs = re.findall(r"!\[.*?\]\((.*?)\)", content)
    if not img_refs:
        result.warn("IMG_COUNT", "ì´ë¯¸ì§€ 0ê°œ (ë‹¤ì´ì–´ê·¸ë¨ ì—†ìŒ?)")
        return

    result.ok("IMG_COUNT", f"ì´ë¯¸ì§€ {len(img_refs)}ê°œ ë°œê²¬")

    for img_url in img_refs:
        # ìƒëŒ€ ê²½ë¡œ â†’ ì ˆëŒ€ URL
        if img_url.startswith("/"):
            full_url = "https://jesamkim.github.io" + img_url
        elif not img_url.startswith("http"):
            full_url = urljoin(base_url, img_url)
        else:
            full_url = img_url

        try:
            resp = requests.head(full_url, timeout=10, allow_redirects=True)
            if resp.status_code == 200:
                result.ok("IMG_ACCESS", f"ì´ë¯¸ì§€ OK: {img_url.split('/')[-1]}")
            else:
                result.error("IMG_ACCESS", f"ì´ë¯¸ì§€ ì ‘ê·¼ ì‹¤íŒ¨ ({resp.status_code}): {img_url.split('/')[-1]}")
        except Exception as e:
            result.error("IMG_ACCESS", f"ì´ë¯¸ì§€ ìš”ì²­ ì‹¤íŒ¨: {img_url.split('/')[-1]} ({e})")


# â”€â”€ 3. Dead link ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_links(content: str, result: QAResult):
    """ì™¸ë¶€ ë§í¬ ì ‘ê·¼ì„± í™•ì¸"""
    import requests

    # ë§ˆí¬ë‹¤ìš´ ë§í¬ ì¶”ì¶œ (ì´ë¯¸ì§€ ì œì™¸)
    links = re.findall(r"(?<!!)\[.*?\]\((https?://[^\)]+)\)", content)
    if not links:
        result.ok("LINKS", "ì™¸ë¶€ ë§í¬ 0ê°œ")
        return

    dead = 0
    for url in links[:20]:  # ìµœëŒ€ 20ê°œë§Œ ê²€ì‚¬
        try:
            resp = requests.head(url, timeout=10, allow_redirects=True,
                                 headers={"User-Agent": "Mozilla/5.0 QA-Bot"})
            if resp.status_code >= 400:
                # GETìœ¼ë¡œ ì¬ì‹œë„ (ì¼ë¶€ ì„œë²„ëŠ” HEAD ê±°ë¶€)
                resp = requests.get(url, timeout=10, allow_redirects=True,
                                    headers={"User-Agent": "Mozilla/5.0 QA-Bot"})
            if resp.status_code >= 400:
                result.error("LINKS_DEAD", f"Dead link ({resp.status_code}): {url[:80]}")
                dead += 1
        except Exception as e:
            result.warn("LINKS_ERR", f"ë§í¬ í™•ì¸ ì‹¤íŒ¨: {url[:60]} ({type(e).__name__})")

    if dead == 0:
        result.ok("LINKS", f"ì™¸ë¶€ ë§í¬ {len(links)}ê°œ ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥")


# â”€â”€ 4. AI ë¬¸ì²´ ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AI_PATTERNS = [
    # ê³¼ì¥/ë¹ˆ ìˆ˜ì‹ì–´
    (r"í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤", "ê³¼ì¥ í‘œí˜„"),
    (r"ë§¤ìš° ì¤‘ìš”í•œ", "ê³¼ì¥ í‘œí˜„"),
    (r"í˜ì‹ ì ì¸ ì ‘ê·¼", "ê³¼ì¥ í‘œí˜„"),
    (r"íšê¸°ì ì¸", "ê³¼ì¥ í‘œí˜„"),
    (r"ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤", "AI íŒ¨í„´"),
    (r"ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤", "AI íŒ¨í„´"),
    (r"ë‹¤ë£¨ì–´ ë³´ê² ìŠµë‹ˆë‹¤", "AI íŒ¨í„´"),

    # AI íŠ¹ìœ  ë„ì…ë¶€
    (r"ê¸‰ë³€í•˜ëŠ”.*ì‹œëŒ€ì—", "AI í´ë¦¬ì…°"),
    (r"ë””ì§€í„¸ ì „í™˜ì˜ ì‹œëŒ€", "AI í´ë¦¬ì…°"),
    (r"ì—†ì–´ì„œëŠ” ì•ˆ ë ", "AI í´ë¦¬ì…°"),

    # ê³¼ë„í•œ ê°•ì¡°
    (r"ë¬´ì—‡ë³´ë‹¤ë„? ì¤‘ìš”í•œ ê²ƒì€", "ê³¼ë„í•œ ê°•ì¡°"),
    (r"ê²°ì½” ê³¼ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤", "ê³¼ë„í•œ ê°•ì¡°"),

    # ë°˜ë§ ì²´í¬ (ì¡´ëŒ“ë§ í†µì¼)
    (r"(?<![ê°€-í£])ì´ë‹¤\.", "ë°˜ë§ (ì¡´ëŒ“ë§ í†µì¼ ìœ„ë°˜)"),
    (r"(?<![ê°€-í£])í•œë‹¤\.", "ë°˜ë§ (ì¡´ëŒ“ë§ í†µì¼ ìœ„ë°˜)"),
    (r"(?<![ê°€-í£])ëœë‹¤\.", "ë°˜ë§ (ì¡´ëŒ“ë§ í†µì¼ ìœ„ë°˜)"),
    (r"(?<![ê°€-í£])ì—†ë‹¤\.", "ë°˜ë§ (ì¡´ëŒ“ë§ í†µì¼ ìœ„ë°˜)"),
    (r"(?<![ê°€-í£])ìˆë‹¤\.", "ë°˜ë§ (ì¡´ëŒ“ë§ í†µì¼ ìœ„ë°˜)"),
]

def check_ai_style(content: str, result: QAResult):
    """AIê°€ ì“´ í‹°ê°€ ë‚˜ëŠ” íŒ¨í„´ ê²€ì‚¬"""
    issues = []
    for pattern, label in AI_PATTERNS:
        matches = re.findall(pattern, content)
        if matches:
            issues.append(f"{label}: '{matches[0]}' ({len(matches)}íšŒ)")

    if issues:
        for issue in issues[:5]:  # ìƒìœ„ 5ê°œë§Œ ë¦¬í¬íŠ¸
            result.warn("AI_STYLE", issue)
        if len(issues) > 5:
            result.warn("AI_STYLE", f"...ì™¸ {len(issues) - 5}ê±´")
    else:
        result.ok("AI_STYLE", "AI ë¬¸ì²´ íŒ¨í„´ ë¯¸ë°œê²¬")


# â”€â”€ 5. ìŠ¤í¬ë¦°ìƒ· (Playwright) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def take_screenshot(url: str, output_path: str, result: QAResult):
    """Playwrightë¡œ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì´¬ì˜"""
    try:
        from playwright.sync_api import sync_playwright
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page(viewport={"width": 1280, "height": 900})
            page.goto(url, wait_until="networkidle", timeout=30000)
            page.screenshot(path=output_path, full_page=True)
            browser.close()
            result.ok("SCREENSHOT", f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {output_path}")
    except ImportError:
        result.warn("SCREENSHOT", "Playwright ë¯¸ì„¤ì¹˜ â€” ìŠ¤í¬ë¦°ìƒ· ìƒëµ")
    except Exception as e:
        result.warn("SCREENSHOT", f"ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {e}")


# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_page(url: str) -> str:
    """ë°°í¬ëœ í˜ì´ì§€ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    import requests
    resp = requests.get(url, timeout=15,
                        headers={"User-Agent": "Mozilla/5.0 QA-Bot"})
    resp.raise_for_status()
    # HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨)
    from html.parser import HTMLParser

    class TextExtractor(HTMLParser):
        def __init__(self):
            super().__init__()
            self.text = []
            self.skip = False

        def handle_starttag(self, tag, attrs):
            if tag in ("script", "style", "nav", "header", "footer"):
                self.skip = True

        def handle_endtag(self, tag):
            if tag in ("script", "style", "nav", "header", "footer"):
                self.skip = False

        def handle_data(self, data):
            if not self.skip:
                self.text.append(data)

    extractor = TextExtractor()
    extractor.feed(resp.text)
    return "\n".join(extractor.text)


def read_local_post(post_path: str) -> str:
    """ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°"""
    with open(post_path, encoding="utf-8") as f:
        return f.read()


def main():
    parser = argparse.ArgumentParser(description="ë°°í¬ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ QA ê²€ìˆ˜")
    parser.add_argument("--url", required=True, help="ë°°í¬ëœ í¬ìŠ¤íŠ¸ URL")
    parser.add_argument("--post", help="ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ì§€ ì°¸ì¡° ì¶”ì¶œìš©)")
    parser.add_argument("--screenshot", action="store_true", help="Playwright ìŠ¤í¬ë¦°ìƒ· ì´¬ì˜")
    parser.add_argument("--screenshot-path", default="/tmp/qa_screenshot.png", help="ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--wait", type=int, default=0, help="ê²€ìˆ˜ ì „ ëŒ€ê¸° ì‹œê°„(ì´ˆ)")
    args = parser.parse_args()

    if args.wait > 0:
        logger.info("â³ ë°°í¬ ì™„ë£Œ ëŒ€ê¸° %dì´ˆ...", args.wait)
        time.sleep(args.wait)

    result = QAResult()

    # í˜ì´ì§€ fetch
    logger.info("ğŸ” ê²€ìˆ˜ ì‹œì‘: %s", args.url)
    try:
        page_text = fetch_page(args.url)
    except Exception as e:
        result.error("FETCH", f"í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        print(json.dumps({"passed": False, "summary": result.summary(), "checks": result.checks}, ensure_ascii=False, indent=2))
        sys.exit(2)

    # ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ (ì´ë¯¸ì§€ ì°¸ì¡°ìš©)
    local_content = None
    if args.post and Path(args.post).exists():
        local_content = read_local_post(args.post)

    # 1. í…ìŠ¤íŠ¸ ê²€ì‚¬ (ë°°í¬ëœ í˜ì´ì§€)
    logger.info("ğŸ“ í…ìŠ¤íŠ¸ ê²€ì‚¬...")
    check_text(page_text, result)

    # 2. ì´ë¯¸ì§€ ì ‘ê·¼ ê²€ì‚¬ (ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ì—ì„œ ê²½ë¡œ ì¶”ì¶œ)
    if local_content:
        logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì ‘ê·¼ ê²€ì‚¬...")
        check_images(local_content, args.url, result)
    else:
        result.warn("IMG_CHECK", "ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ ì—†ìŒ â€” ì´ë¯¸ì§€ ê²€ì‚¬ ìƒëµ")

    # 3. Dead link ê²€ì‚¬
    if local_content:
        logger.info("ğŸ”— Dead link ê²€ì‚¬...")
        check_links(local_content, result)

    # 4. AI ë¬¸ì²´ ê²€ì‚¬
    logger.info("âœï¸ AI ë¬¸ì²´ ê²€ì‚¬...")
    check_ai_style(page_text, result)

    # 5. ìŠ¤í¬ë¦°ìƒ·
    if args.screenshot:
        logger.info("ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì´¬ì˜...")
        take_screenshot(args.url, args.screenshot_path, result)

    # ê²°ê³¼ ì¶œë ¥
    print()
    print("=" * 60)
    print(result.summary())
    print("=" * 60)
    for check in result.checks:
        icon = {"OK": "âœ…", "WARN": "âš ï¸", "ERROR": "âŒ"}[check["status"]]
        print(f"  {icon} [{check['category']}] {check['message']}")

    # JSON ë¡œê·¸ ì €ì¥
    log_path = Path("/tmp/qa_result.json")
    with open(log_path, "w", encoding="utf-8") as f:
        json.dump({
            "url": args.url,
            "passed": result.passed,
            "summary": result.summary(),
            "errors": len(result.errors),
            "warnings": len(result.warnings),
            "checks": result.checks,
        }, f, ensure_ascii=False, indent=2)
    logger.info("ğŸ“‹ ê²°ê³¼ ì €ì¥: %s", log_path)

    sys.exit(0 if result.passed else 1)


if __name__ == "__main__":
    main()
